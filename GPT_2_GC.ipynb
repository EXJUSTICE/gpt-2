{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2_GC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI-HVDbQS9dF",
        "colab_type": "text"
      },
      "source": [
        "# Generating Fake News with OpenAI’s GPT-2 Language Model\n",
        "\n",
        "## Background\n",
        "\n",
        "This notebook is a stripped down version of the original notebook by Lopez, Francos (ilopezfr), in order to support the tutorial on GradientCrescent.\n",
        "\n",
        "In this Jupyter notebook you can play around with of **Open AI's GPT-2** Language Model from the paper **[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)**. \n",
        "\n",
        "You'll be able to choose between the small (**117M** parameters) , medium (**345M** parameters), large (**774M** parameters) and XL versions (**1.5B** parameters) version of GPT-2, in the second cell code block.\n",
        "Conditional sample genretion is implemented, simply type in seed words when prompted in the console.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RifDMqnj_nhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "c415fa51-9f68-485f-d0be-1591c294651b"
      },
      "source": [
        "import os\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=f638d743e263b34c07ea0473b6522dcd1c20615882151e9317b75910eb22cafe\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKqlSCrpS9dH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52158635-2b48-4cea-8c31-c2ee380041f2"
      },
      "source": [
        "!git clone https://github.com/EXJUSTICE/gpt-2/\n",
        "os.chdir('gpt-2')\n",
        "!python download_model.py 117M\n",
        "# !python download_model.py 345M\n",
        "#!python download_model.py 774M\n",
        "#!python download_model.py 1558M\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 313 (delta 0), reused 0 (delta 0), pack-reused 310\u001b[K\n",
            "Receiving objects: 100% (313/313), 4.64 MiB | 13.72 MiB/s, done.\n",
            "Resolving deltas: 100% (174/174), done.\n",
            "Fetching checkpoint: 1.00kit [00:00, 928kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 31.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 793kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:11, 45.0Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 2.86Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 27.6Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 22.8Mit/s]                                                       \n",
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hCollecting regex==2018.1.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f4/7146c3812f96fcaaf2d06ff6862582302626a59011ccb6f2833bb38d80f7/regex-2018.01.10.tar.gz (612kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 9.5MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.4.5.2)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=b04a786f75bb6eee37b8153858e18ed29df526c7258445e3456f2c6cc6e007c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2018.1.10-cp36-cp36m-linux_x86_64.whl size=548010 sha256=332fe5bec7b5f8126afc403f60cb641bf082e7ebac64826fe073ad009cc659ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/17/3f/c77bba99efd74ba1a19862c9dd97f4b6d735e2826721dc00ff\n",
            "Successfully built fire regex\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex, idna, requests, tqdm\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: idna 2.9\n",
            "    Uninstalling idna-2.9:\n",
            "      Successfully uninstalled idna-2.9\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed fire-0.3.1 idna-2.8 regex-2018.1.10 requests-2.21.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAyrz11CWmZI",
        "colab_type": "text"
      },
      "source": [
        "## Conditional sample generation\n",
        "\n",
        "To generate conditional samples from the small model:\n",
        "```\n",
        "!python3 src/interactive_conditional_samples.py\n",
        "```\n",
        "It comes with a few flags available, with a default value: \n",
        "-  `model_name = '117M' ` : choose between 117M, 345M, 774M, and 1558M models. By default is 117M. \n",
        "- `seed = None`  || a random value is generated unless specified. give a specific integer value if you want to reproduce same results in the future.\n",
        "- `nsamples = 1`     ||  specify the number of samples you want to print\n",
        "- `length = None`   ||  number of tokens (words) to print on each sample.\n",
        "- `batch_size= 1`  ||  how many inputs you want to process simultaneously. *only affects speed/memory* \n",
        "- `temperature = 1`  ||  float between 0 and 1. scales logits before sampling prior to softmax. higher temperature results in more random completions.\n",
        "- `top_k = 0`   ||  Integer value controlling diversity.  Truncates the set of logits considered to those with the highest values. 1 means only 1 word is considered for each step (token), resulting in deterministic completions. 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value.\n",
        "\n",
        "\n",
        "\n",
        "The authors tested the model performance on a few different language tasks, including **reading comprehension, text completion, summarization, translation, and question-answering.**\n",
        "\n",
        "Below are a few examples selected to test the aforementioned behaviors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QIdaQn5WkSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67517d9d-1317-4612-b11d-68c73055c3c4"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --model_name='117M' --nsamples=2 --top_k=40 --temperature=.80"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-06-19 15:03:00.907608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-19 15:03:00.963437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:00.964244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-19 15:03:00.984939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-19 15:03:01.264215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-19 15:03:01.389845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-19 15:03:01.415028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-19 15:03:01.684522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-19 15:03:01.873055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-19 15:03:02.455712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-19 15:03:02.455992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.456897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.457625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-19 15:03:02.458051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-06-19 15:03:02.462814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-06-19 15:03:02.463074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ac32c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-19 15:03:02.463111: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-19 15:03:02.553295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.554199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ac3480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-19 15:03:02.554236: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-06-19 15:03:02.555615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.556375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-19 15:03:02.556463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-19 15:03:02.556516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-06-19 15:03:02.556568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-06-19 15:03:02.556620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-06-19 15:03:02.556696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-06-19 15:03:02.556751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-06-19 15:03:02.556802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-19 15:03:02.556953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.557778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.558479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-06-19 15:03:02.558553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-06-19 15:03:02.560370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-19 15:03:02.560408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-06-19 15:03:02.560426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-06-19 15:03:02.560598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.561417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-19 15:03:02.562147: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-06-19 15:03:02.562200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Model prompt >>> police brutality\n",
            "2020-06-19 15:03:34.406062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            " and murder. That's why we have to take a stand against this kind of violence and to demand that they stop.\"\n",
            "\n",
            "The bill was approved by a special commission in April, which also recommended a ban on the use of tear gas. The council has asked the state to consider whether state law should prohibit the use of tear gas in a city.\n",
            "\n",
            "Copyright 2017 KING<|endoftext|>Somewhere between that and the last few days of April I had the pleasure of reading a recent post by Mark Shulman on the subject of \"How and when to stop watching television\". I'm not going to give away too much of the details.\n",
            "\n",
            "I don't mean to go into my own thoughts here, I merely want to say that it is not my place to go into all the details of the subject. In particular, it is not my place to focus on any particular aspect like how we should handle television.\n",
            "\n",
            "There is a lot of time for the individual to focus on their own work and that makes sense. But there is also a point of focus where time is the most important thing. For those of us who have spent a lot of time on TV or video games, it is not the most important thing.\n",
            "\n",
            "The fact that a large proportion of fans of television shows are watching those shows with their TVs is quite interesting to me because it means that there are more viewers of the show than of games and video games.\n",
            "\n",
            "It also means we are less likely to have to watch the show to see what it tells us about the individual.\n",
            "\n",
            "There are plenty of games about video games and gaming shows and even games about television and video games on the Internet. This is a big part of the appeal of some of these shows. I've certainly not played them in this way.\n",
            "\n",
            "But one of the main reasons I play a lot of video games is that I feel that I can go to games that I like. That is the way to describe what I do in the video game world.\n",
            "\n",
            "One of the best games I've played where I was able to get to grips with the world of video games is \"Astro City\".\n",
            "\n",
            "The game is actually pretty similar in many ways to the game \"Sonic the Hedgehog\".\n",
            "\n",
            "It is almost like a \"manga\" to the genre, but it is not about fighting, it is about the game.\n",
            "\n",
            "There are the usual things like \"Tiger Woods is a robot\" and \"Cadbury is a giant\n",
            "======================================== SAMPLE 2 ========================================\n",
            ".\n",
            "\n",
            "The court heard how a man who had gone to a friend's home to meet up with another woman told the girl he wanted to talk about what had happened.\n",
            "\n",
            "The woman told police that she had gone to the home to meet the man.\n",
            "\n",
            "During the course of the meeting, the girl told police she heard the man shout \"Allahu Akbar\" and then go to the house.\n",
            "\n",
            "She said the man then went downstairs to tell her it was over.\n",
            "\n",
            "The girl said she was surprised to hear the man then go downstairs to meet up again.\n",
            "\n",
            "She said the man then went up and punched her in the face again and then proceeded to go out again.\n",
            "\n",
            "The court heard that the victim told police she was walking along the street when she was approached by another man.\n",
            "\n",
            "He then punched her in the face and said: \"You are so rude, we are going to be murderers.\"\n",
            "\n",
            "She said she then became aggressive with him. He then left.\n",
            "\n",
            "The court heard the man told police he had come to meet her and that he had been \"taken aback\" by her behaviour.\n",
            "\n",
            "The court heard the man said: \"You seem like you can't understand people. You're rude and I'm going to kill you.\"\n",
            "\n",
            "She said she was \"sad\" and \"shocked\" at this, and the man then left and the girl ran to a nearby pub.\n",
            "\n",
            "The court heard she called 999 but never called the police.\n",
            "\n",
            "The court heard at the time she was at the house and the man, who was in his late 50s with a long face, told her to \"keep quiet\" and \"get on with your life\".\n",
            "\n",
            "He told the girl-who said he was from Pakistan, that he had come to meet her for \"getting to know the girl and that he wanted her to tell her all her stories\".\n",
            "\n",
            "But when she asked him to leave her house, the man said: \"No you can't\".\n",
            "\n",
            "The court heard he told the victim that he had been \"stuck\" on the street with a black man who had punched her.\n",
            "\n",
            "The victim told police the man went outside and saw the woman walking along the street.\n",
            "\n",
            "He told the court he had been \"taken aback\" at that and that he had asked her to leave the house.\n",
            "\n",
            "He was later arrested on the charge of possessing a dangerous weapon of a dangerous nature\n",
            "================================================================================\n",
            "Model prompt >>> police brutality\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}